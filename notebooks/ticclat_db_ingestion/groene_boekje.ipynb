{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groene boekje\n",
    "* Use `dbutils.add_lexicon`!\n",
    "* Use `bulk_add_anahashes` and `connect_anahases_to_wordforms`\n",
    "\n",
    "INL takse about 3 minutes (without anahashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ticclat.dbutils\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "* Add relationships between models (should make processing an xml file faster)\n",
    "* Use sessions better: https://docs.sqlalchemy.org/en/latest/orm/session_basics.html#when-do-i-construct-a-session-when-do-i-commit-it-and-when-do-i-close-it\n",
    "* Add multiple documents\n",
    "* Extract vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read information to connect to the database and put it in environment variables\n",
    "import os\n",
    "with open('ENVVARS.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.split('=')\n",
    "        if len(parts) == 2:\n",
    "            os.environ[parts[0]] = parts[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'ticclat'\n",
    "os.environ['dbname'] = db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "\n",
    "engine = create_engine(\"mysql://{}:{}@localhost/{}\".format(os.environ['user'], \n",
    "                                                           os.environ['password'], \n",
    "                                                           os.environ['dbname']))\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "\n",
    "print(database_exists(engine.url))\n",
    "\n",
    "Session = sessionmaker(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ticclat.lexicon_schema import AnalyzedWordform, Document, Lemmata, TokenAttestation, Wordform, Base\n",
    "import ticclat.ticclat_schema as schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tables\n",
    "schema.Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import inspect\n",
    "\n",
    "inspector = inspect(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anahashes', 'corpora', 'corpusId_x_documentId', 'documents', 'lexica', 'lexical_source_wordform', 'source_x_wordform_link', 'text_attestations', 'wordform_links', 'wordforms']\n"
     ]
    }
   ],
   "source": [
    "# Get table information\n",
    "print(inspector.get_table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Groene Boekje data into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_basepath = \"/Users/pbos/projects/ticclat/data/GB/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB1914_path = GB_basepath + \"1914/22722-8.txt\"\n",
    "GB1995_path = GB_basepath + \"1995-2005/1995/GB95_002.csv\"\n",
    "GB2005_path = GB_basepath + \"1995-2005/2005/GB05_002.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GB1995 = pd.read_csv(GB1995_path, sep=';', names=[\"word\", \"syllables\", \"see also\", \"disambiguation\",\n",
    "                                                     \"grammatical tag\", \"article\",\n",
    "                                                     \"plural/past/attrib\", \"plural/past/attrib syllables\",\n",
    "                                                     \"diminu/compara/past plural\", \"diminu/compara/past plural syllables\",\n",
    "                                                     \"past perfect/superla\", \"past perfect/superla syllables\"],\n",
    "                        encoding='utf8') # encoding necessary for later loading into sqlalchemy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_GB1995\n",
    "# df_GB1995['see also'].dropna().map(lambda x: x[:8]).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of stuff in there... clean up time.\n",
    "\n",
    "Multiple columns:\n",
    "- Some entries have \"@\" in them. They seem to be general rules for some kinds of words. Not sure what to do with these, so will just filter out for now.\n",
    "\n",
    "First column:\n",
    "- Has entries with multiple values (e.g. \"Zwols, Zwoller\")\n",
    "- Sometimes has multiple rows with the same word, probably in different meanings or something, e.g. \"aal1\", \"aal2\" and \"aal3\".\n",
    "    + In this case, the fourth column has a note to disambiguate the meanings.\n",
    "\n",
    "Second column: Splits words according to syllables, we can disregard this.\n",
    "\n",
    "Third: a \"See also \\[other word\\]\" note (they all start with \"Zie ook\")\n",
    "\n",
    "Fourth: disambiguation of a duplicate word (see first column)\n",
    "\n",
    "Fifth: grammatical tag, i.e. noun, adjective, verb, etc.\n",
    "\n",
    "Sixth: the proper definite article for the noun (\"de\" or \"het\").\n",
    "\n",
    "Seventh: first inflection form. Sometimes left empty.\n",
    "- If a noun: plural form\n",
    "- If a verb: past tense singular\n",
    "- If an adjective (or pronoun (`vnw.`)): attributive form\n",
    "\n",
    "Nineth: second inflection form. Often left empty, probably for regular or easy forms.\n",
    "- If a noun: diminutive\n",
    "- If an adjective: comparative\n",
    "- If a verb: past tense plural\n",
    "\n",
    "Eleventh:\n",
    "- If a verb: past perfect (voltooid verleden tijd?)\n",
    "- If an adjective: superlative\n",
    "\n",
    "8, 10, 12: Syllables of the preceding.\n",
    "\n",
    "## Clean up\n",
    "\n",
    "### Wordforms\n",
    "- 1 needs most work:\n",
    "  + Split up if it has a comma and two (or more) words --> Make it two (or more) rows; check that the other columns also have **the same number** of comma separated words and match those, otherwise just duplicate other columns.\n",
    "  + Make a new column for rows with a \"duplicate entry number\" postfixed; put the number there, remove it from the first row.\n",
    "    - Note that column 3 also uses the postfix number to refer to specific duplicates!\n",
    "- 2, 8, 10 and 12 can go, we have no need for pronunciation information currently.\n",
    "- We have no place in the current schema for 5, so we drop it as well for now.\n",
    "- Column 3 is for links only.\n",
    "- Columns 7, 9 and 11 also contain wordforms, so we give these their own rows as well. For now, we don't need links, so we just extract the words and worry about efficient linking later.\n",
    "\n",
    "### Links\n",
    "This lexicon also contains a lot of word links.\n",
    "\n",
    "- Obviously, the three inflection columns, 7 9 and 11, give clear immediate links between wordforms, i.e. grammatical ones.\n",
    "- Column 3 also gives a link, of words with similar meanings, i.e. a semantic link.\n",
    "\n",
    "### Grammatical function\n",
    "Column 5 may at some point be used to add grammatical information, if we ever plan on using this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual wordforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GB1995_wordforms = df_GB1995.drop([\"syllables\", \"see also\", \"disambiguation\", \"grammatical tag\", \"article\",\n",
    "                                      \"plural/past/attrib syllables\", \"diminu/compara/past plural syllables\", \"past perfect/superla syllables\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>plural/past/attrib</th>\n",
       "      <th>diminu/compara/past plural</th>\n",
       "      <th>past perfect/superla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24334</th>\n",
       "      <td>endocrinoloog</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64178</th>\n",
       "      <td>openingsbeeld</td>\n",
       "      <td>openingsbeelden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2405</th>\n",
       "      <td>afrekening</td>\n",
       "      <td>afrekeningen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22143</th>\n",
       "      <td>driekleur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96519</th>\n",
       "      <td>venkelwater</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102361</th>\n",
       "      <td>voorwas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90090</th>\n",
       "      <td>temporeel</td>\n",
       "      <td>temporele</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96691</th>\n",
       "      <td>verbintenis</td>\n",
       "      <td>verbintenissen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52527</th>\n",
       "      <td>maatverdeling</td>\n",
       "      <td>maatverdelingen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35614</th>\n",
       "      <td>heroi@\\sering\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word plural/past/attrib diminu/compara/past plural  \\\n",
       "24334    endocrinoloog                NaN                        NaN   \n",
       "64178    openingsbeeld    openingsbeelden                        NaN   \n",
       "2405        afrekening       afrekeningen                        NaN   \n",
       "22143        driekleur                NaN                        NaN   \n",
       "96519      venkelwater                NaN                        NaN   \n",
       "102361         voorwas                NaN                        NaN   \n",
       "90090        temporeel          temporele                        NaN   \n",
       "96691      verbintenis     verbintenissen                        NaN   \n",
       "52527    maatverdeling    maatverdelingen                        NaN   \n",
       "35614   heroi@\\sering\"                NaN                        NaN   \n",
       "\n",
       "       past perfect/superla  \n",
       "24334                   NaN  \n",
       "64178                   NaN  \n",
       "2405                    NaN  \n",
       "22143                   NaN  \n",
       "96519                   NaN  \n",
       "102361                  NaN  \n",
       "90090                   NaN  \n",
       "96691                   NaN  \n",
       "52527                   NaN  \n",
       "35614                   NaN  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GB1995_wordforms.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ongespecif.', 'znw.', 'bnw.', 'ww.min_zich', 'uitdr.', 'bijw.',\n",
       "       'voorz.', 'voegw.', 'ww.met_zich', 'eigenn.', 'telw.', 'vnw.',\n",
       "       'de', nan, 'lidw.', 'het', 'tw.'], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GB1995[\"grammatical tag\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>syllables</th>\n",
       "      <th>see also</th>\n",
       "      <th>disambiguation</th>\n",
       "      <th>grammatical tag</th>\n",
       "      <th>article</th>\n",
       "      <th>plural/past/attrib</th>\n",
       "      <th>plural/past/attrib syllables</th>\n",
       "      <th>diminu/compara/past plural</th>\n",
       "      <th>diminu/compara/past plural syllables</th>\n",
       "      <th>past perfect/superla</th>\n",
       "      <th>past perfect/superla syllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32039</th>\n",
       "      <td>goh</td>\n",
       "      <td>goh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tw.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41036</th>\n",
       "      <td>jemig</td>\n",
       "      <td>je/mig</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tw.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83036</th>\n",
       "      <td>soit</td>\n",
       "      <td>soit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tw.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word syllables see also disambiguation grammatical tag article  \\\n",
       "32039    goh       goh      NaN            NaN             tw.     NaN   \n",
       "41036  jemig    je/mig      NaN            NaN             tw.     NaN   \n",
       "83036   soit      soit      NaN            NaN             tw.     NaN   \n",
       "\n",
       "      plural/past/attrib plural/past/attrib syllables  \\\n",
       "32039                NaN                          NaN   \n",
       "41036                NaN                          NaN   \n",
       "83036                NaN                          NaN   \n",
       "\n",
       "      diminu/compara/past plural diminu/compara/past plural syllables  \\\n",
       "32039                        NaN                                  NaN   \n",
       "41036                        NaN                                  NaN   \n",
       "83036                        NaN                                  NaN   \n",
       "\n",
       "      past perfect/superla past perfect/superla syllables  \n",
       "32039                  NaN                            NaN  \n",
       "41036                  NaN                            NaN  \n",
       "83036                  NaN                            NaN  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GB1995[df_GB1995[\"grammatical tag\"] == 'tw.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should probably skip `uitdr.` (sayings). Maybe also `eigenn.` (proper names). Will leave them in for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordform clean up\n",
    "\n",
    "## Mysterious \"@\" rows\n",
    "Let's take out the weird \"@\" rows first to see what we can do with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nd_any(*args):\n",
    "    result = (args[0] | args[0])\n",
    "    for arg in args:\n",
    "        result = (result | arg)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GB1995_at = df_GB1995[nd_any(*tuple(df_GB1995[col].str.contains('@') for col in df_GB1995.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>syllables</th>\n",
       "      <th>see also</th>\n",
       "      <th>disambiguation</th>\n",
       "      <th>grammatical tag</th>\n",
       "      <th>article</th>\n",
       "      <th>plural/past/attrib</th>\n",
       "      <th>plural/past/attrib syllables</th>\n",
       "      <th>diminu/compara/past plural</th>\n",
       "      <th>diminu/compara/past plural syllables</th>\n",
       "      <th>past perfect/superla</th>\n",
       "      <th>past perfect/superla syllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42104</th>\n",
       "      <td>kampeerauto</td>\n",
       "      <td>kam/peer/au/to</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>znw.</td>\n",
       "      <td>de[m.]</td>\n",
       "      <td>kampeerauto@@s</td>\n",
       "      <td>kam/peer/au/to@@s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24520</th>\n",
       "      <td>enque@^tering</td>\n",
       "      <td>en/que@^/te/ring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>znw.</td>\n",
       "      <td>de[v.]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15822</th>\n",
       "      <td>cinema</td>\n",
       "      <td>ci/ne/ma</td>\n",
       "      <td>zie ook kinema</td>\n",
       "      <td>NaN</td>\n",
       "      <td>znw.</td>\n",
       "      <td>de[m.]</td>\n",
       "      <td>cinema@@s</td>\n",
       "      <td>ci/ne/ma@@s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14722</th>\n",
       "      <td>buurtcomite@'</td>\n",
       "      <td>buurt/co/mi/te@'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>znw.</td>\n",
       "      <td>het</td>\n",
       "      <td>buurtcomite@'s</td>\n",
       "      <td>buurt/co/mi/te@'s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word         syllables        see also disambiguation  \\\n",
       "42104    kampeerauto    kam/peer/au/to             NaN            NaN   \n",
       "24520  enque@^tering  en/que@^/te/ring             NaN            NaN   \n",
       "15822         cinema          ci/ne/ma  zie ook kinema            NaN   \n",
       "14722  buurtcomite@'  buurt/co/mi/te@'             NaN            NaN   \n",
       "\n",
       "      grammatical tag article plural/past/attrib plural/past/attrib syllables  \\\n",
       "42104            znw.  de[m.]     kampeerauto@@s            kam/peer/au/to@@s   \n",
       "24520            znw.  de[v.]                NaN                          NaN   \n",
       "15822            znw.  de[m.]          cinema@@s                  ci/ne/ma@@s   \n",
       "14722            znw.     het     buurtcomite@'s            buurt/co/mi/te@'s   \n",
       "\n",
       "      diminu/compara/past plural diminu/compara/past plural syllables  \\\n",
       "42104                        NaN                                  NaN   \n",
       "24520                        NaN                                  NaN   \n",
       "15822                        NaN                                  NaN   \n",
       "14722                        NaN                                  NaN   \n",
       "\n",
       "      past perfect/superla past perfect/superla syllables  \n",
       "42104                  NaN                            NaN  \n",
       "24520                  NaN                            NaN  \n",
       "15822                  NaN                            NaN  \n",
       "14722                  NaN                            NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GB1995_at.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_GB1995_at.values.flatten()\n",
    "x = pd.Series(x).dropna().to_frame()\n",
    "x = x[x[0].str.contains('@')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ats = x[0].str.extract('(\\@[^\\w]*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@`', '@@', \"@'\", '@\\\\', '@`/', '@\\\\/', '@` ', \"@'/\", '@\\\\\";',\n",
       "       '@\\\\@@', '@+', '@^', '@^/', \"@'-\", \"@' \", '@', '@@ ', '@=', '@`-',\n",
       "       '@\\\\-'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ats[0].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahhh, they seem to be diacritic markers!\n",
    "- @\\` is accent grave on the previous character\n",
    "- @\\' is accent aigu on the previous character\n",
    "- @@ seems to be apostrophe\n",
    "\n",
    "But then... a whole zoo of quite rare ones. Let's check out examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              0\n",
      "0                           a@`\n",
      "1                           a@`\n",
      "204       achtervolgingssce@`ne\n",
      "205  ach/ter/vol/gings/sce@`/ne\n",
      "468            afscheidssce@`ne\n",
      "                      0\n",
      "18                 a@@s\n",
      "19                 a@@s\n",
      "20               a@@tje\n",
      "21               a@@tje\n",
      "42  aankoopprogramma@@s\n",
      "                              0\n",
      "24         aanbevelingscomite@'\n",
      "25   aan/be/ve/lings/co/mi/te@'\n",
      "240               actiecomite@'\n",
      "241           ac/tie/co/mi/te@'\n",
      "246              actiecomite@'s\n",
      "                    0\n",
      "78       aardolie@\\n\"\n",
      "79     aard/oli/e@\\n\"\n",
      "96      abiturie@\\nt\"\n",
      "97   abi/tu/ri/e@\\nt\"\n",
      "102   abiturie@\\nten\"\n",
      "                               0\n",
      "205   ach/ter/vol/gings/sce@`/ne\n",
      "469          af/scheids/sce@`/ne\n",
      "1009                  am/pe@`/re\n",
      "1015                 am/pe@`/res\n",
      "1021           am/pe@`/re/me/ter\n",
      "                      0\n",
      "283  ac/tu/a/ri/e@\\/le\"\n",
      "301      ade/no/i@\\/de\"\n",
      "307     ade/no/i@\\/den\"\n",
      "325       ae@\\/ro/club\"\n",
      "331      ae@\\/ro/clubs\"\n",
      "                  0\n",
      "504        a@` gogo\n",
      "505       a@` go/go\n",
      "1428     a@` propos\n",
      "1429    a@` pro/pos\n",
      "4236  bric a@` brac\n",
      "                            0\n",
      "553         ai/de-me@'/moi/re\n",
      "1957      at/ta/che@'/kof/fer\n",
      "1963     at/ta/che@'/kof/fers\n",
      "1965  at/ta/che@'/kof/fer/tje\n",
      "3985             bo/he@'/mien\n",
      "                                 0\n",
      "780               aloe@\\\";aloe@\\\"\"\n",
      "3156         Belgie@\\\";Bel/gie@\\\"\"\n",
      "3204         benzoe@\\\";ben/zoe@\\\"\"\n",
      "10980     Eurazie@\\\";Eur/a/zie@\\\"\"\n",
      "11670  extranei@\\\";ex/tra/ne/i@\\\"\"\n",
      "               0\n",
      "785   aloe@\\@@s\"\n",
      "786  alo/e@\\@@s\"\n",
      "         0\n",
      "0      a@`\n",
      "1      a@`\n",
      "18    a@@s\n",
      "19    a@@s\n",
      "20  a@@tje\n",
      "Empty DataFrame\n",
      "Columns: [0]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [0]\n",
      "Index: []\n",
      "                       0\n",
      "4524     cafe@'-chantant\n",
      "4525   ca/fe@'-chan/tant\n",
      "4530    cafe@'-chantants\n",
      "4531  ca/fe@'-chan/tants\n",
      "4548     cafe@'-eigenaar\n",
      "                     0\n",
      "4536    cafe@' complet\n",
      "4537  ca/fe@' com/plet\n",
      "         0\n",
      "0      a@`\n",
      "1      a@`\n",
      "18    a@@s\n",
      "19    a@@s\n",
      "20  a@@tje\n",
      "                            0\n",
      "6456     commedia dell@@ arte\n",
      "6457  com/me/dia dell@@ ar/te\n",
      "                0\n",
      "8988       don@=a\n",
      "8989      do/n@=a\n",
      "8994    don@=a@@s\n",
      "8995   do/n@=a@@s\n",
      "31908     sen@=or\n",
      "                     0\n",
      "11736    face-a@`-main\n",
      "11737   fa/ce-a@`-main\n",
      "11742   face-a@`-mains\n",
      "11743  fa/ce-a@`-mains\n",
      "26268   pied-a@`-terre\n",
      "                            0\n",
      "12144         fidei@\\-commis\"\n",
      "12145      fi/de/i@\\-com/mis\"\n",
      "12150      fidei@\\-commissen\"\n",
      "12151  fi/de/i@\\-com/mis/sen\"\n"
     ]
    }
   ],
   "source": [
    "for at in ats[0].unique():\n",
    "    print(x[ats[0].str.contains(at.replace('\\\\', \"\\\\\\\\\"))].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so the three-character ones seem to be wrong: / are all just syllable separators, with a - behind them are just koppeltekens, with space is just space, etc., so let's cut it down to a two-character filter (actually also just one, there's a naked @ as well... though is that one actually naked or does the following character there also have special meaning? **make sure**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ats = x[0].str.extract('(\\@[^\\w]?)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@`', '@@', \"@'\", '@\\\\', '@+', '@^', '@', '@='], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ats[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@`\n",
      "                              0\n",
      "0                           a@`\n",
      "1                           a@`\n",
      "204       achtervolgingssce@`ne\n",
      "205  ach/ter/vol/gings/sce@`/ne\n",
      "468            afscheidssce@`ne\n",
      "@@\n",
      "                      0\n",
      "18                 a@@s\n",
      "19                 a@@s\n",
      "20               a@@tje\n",
      "21               a@@tje\n",
      "42  aankoopprogramma@@s\n",
      "@'\n",
      "                              0\n",
      "24         aanbevelingscomite@'\n",
      "25   aan/be/ve/lings/co/mi/te@'\n",
      "240               actiecomite@'\n",
      "241           ac/tie/co/mi/te@'\n",
      "246              actiecomite@'s\n",
      "@\\\n",
      "                    0\n",
      "78       aardolie@\\n\"\n",
      "79     aard/oli/e@\\n\"\n",
      "96      abiturie@\\nt\"\n",
      "97   abi/tu/ri/e@\\nt\"\n",
      "102   abiturie@\\nten\"\n",
      "@+\n",
      "                 0\n",
      "1296      aperc@+u\n",
      "1297     aper/c@+u\n",
      "1302   aperc@+u@@s\n",
      "1303  aper/c@+u@@s\n",
      "2328  bagagerec@+u\n",
      "@^\n",
      "                          0\n",
      "3816       bliksemenque@^te\n",
      "3817   blik/sem/en/que@^/te\n",
      "7284    cou@^te que cou@^te\n",
      "7285  cou@^/te que cou@^/te\n",
      "7416                cre@^pe\n",
      "@\n",
      "         0\n",
      "0      a@`\n",
      "1      a@`\n",
      "18    a@@s\n",
      "19    a@@s\n",
      "20  a@@tje\n",
      "@=\n",
      "                0\n",
      "8988       don@=a\n",
      "8989      do/n@=a\n",
      "8994    don@=a@@s\n",
      "8995   do/n@=a@@s\n",
      "31908     sen@=or\n"
     ]
    }
   ],
   "source": [
    "for at in ats[0].unique():\n",
    "    print(at)\n",
    "    print(x[ats[0].str.contains(at.replace('\\\\', \"\\\\\\\\\").replace('+', \"\\+\").replace('^', \"\\^\"))].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- @\\` is accent grave on the previous character\n",
    "- @\\' is accent aigu\n",
    "- @\\\\ is trema\n",
    "- @+ is cedilla\n",
    "- @^ is accent circumflex\n",
    "- @= is a tilde\n",
    "- @@ is apostrophe between the characters\n",
    "\n",
    "The naked @ requires a bit more work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "naked_at = x[~nd_any(*tuple(ats[0].str.contains(at.replace('\\\\', \"\\\\\\\\\").replace('+', \"\\+\").replace('^', \"\\^\")) for at in ats[0].unique() if at != '@'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5892</th>\n",
       "      <td>CO@2-emissie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5898</th>\n",
       "      <td>CO@2-emissies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>CO@2-heffing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>CO@2-probleem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18618</th>\n",
       "      <td>kadeee@n, kadees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18702</th>\n",
       "      <td>kakofoniee@n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18726</th>\n",
       "      <td>kalligrafiee@n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18774</th>\n",
       "      <td>kankertherapiee@n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18930</th>\n",
       "      <td>kerkprovincies, kerkprovincie@n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18942</th>\n",
       "      <td>kernideee@n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19050</th>\n",
       "      <td>kilocaloriee@n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19194</th>\n",
       "      <td>kleinoden, kleinodie@n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19242</th>\n",
       "      <td>kleurenkopiee@n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19362</th>\n",
       "      <td>kniee@n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19386</th>\n",
       "      <td>koekendriee@n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19422</th>\n",
       "      <td>kolonie@n, kolonies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19506</th>\n",
       "      <td>kopiee@n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19638</th>\n",
       "      <td>kroonkolonies, kroonkolonie@n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19770</th>\n",
       "      <td>kweee@n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19782</th>\n",
       "      <td>kweee@n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0\n",
       "5892                      CO@2-emissie\n",
       "5898                     CO@2-emissies\n",
       "5904                      CO@2-heffing\n",
       "5916                     CO@2-probleem\n",
       "18618                 kadeee@n, kadees\n",
       "18702                     kakofoniee@n\n",
       "18726                   kalligrafiee@n\n",
       "18774                kankertherapiee@n\n",
       "18930  kerkprovincies, kerkprovincie@n\n",
       "18942                      kernideee@n\n",
       "19050                   kilocaloriee@n\n",
       "19194           kleinoden, kleinodie@n\n",
       "19242                  kleurenkopiee@n\n",
       "19362                          kniee@n\n",
       "19386                    koekendriee@n\n",
       "19422              kolonie@n, kolonies\n",
       "19506                         kopiee@n\n",
       "19638    kroonkolonies, kroonkolonie@n\n",
       "19770                          kweee@n\n",
       "19782                          kweee@n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naked_at[~naked_at[0].str.contains('/')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so the presumed naked @ is actually two possible things I wrongly filtered out:\n",
    "- @2 is 2 in subscript, as in CO$_2$ (and only that)\n",
    "- @n comes exclusively before an e that should have a trema on it; the backslash that's normally used is probably omitted to avoid confusion with newline-character \\\\n\n",
    "\n",
    "We will normalize the diacritics below when we have gathered all wordforms in one array, for easier processing.\n",
    "\n",
    "## Gather wordforms\n",
    "\n",
    "Now to gather all actual wordforms, i.e. those in columns 1, 7, 9 and 11, also splitting by comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordform_df = pd.concat((df_GB1995[\"word\"], df_GB1995[df_GB1995.columns[6]], df_GB1995[df_GB1995.columns[8]], df_GB1995[df_GB1995.columns[10]]))\\\n",
    "                .dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100      aandachtstreep, aandachtsstreep\n",
       "104    aandachttrekker, aandachtstrekker\n",
       "747                   aanvraag, aanvrage\n",
       "767        aan weerszijden, aan weerszij\n",
       "997                   Aarlenaar, Arelaar\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform_df[wordform_df.str.contains(', ')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94097        UFO@@tje:\n",
       "66631          paatje:\n",
       "23720        EHBO@@er:\n",
       "15228       caviaatje:\n",
       "14885     cameliaatje:\n",
       "23151        echootje:\n",
       "21969       dramaatje:\n",
       "16307       collietje:\n",
       "90331    teringzootje:\n",
       "14953      canapeetje:\n",
       "dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform_df[wordform_df.str.contains(':')].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ffs, some words have colons in them, what do those mean then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GB1995_colon = df_GB1995[nd_any(*tuple(df_GB1995[col].str.contains(':') for col in df_GB1995.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>syllables</th>\n",
       "      <th>see also</th>\n",
       "      <th>disambiguation</th>\n",
       "      <th>grammatical tag</th>\n",
       "      <th>article</th>\n",
       "      <th>plural/past/attrib</th>\n",
       "      <th>plural/past/attrib syllables</th>\n",
       "      <th>diminu/compara/past plural</th>\n",
       "      <th>diminu/compara/past plural syllables</th>\n",
       "      <th>past perfect/superla</th>\n",
       "      <th>past perfect/superla syllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>abc</td>\n",
       "      <td>abc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>znw.</td>\n",
       "      <td>het</td>\n",
       "      <td>abc@@s</td>\n",
       "      <td>abc@@s</td>\n",
       "      <td>abc@@tje:</td>\n",
       "      <td>abc/tje</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>acacia</td>\n",
       "      <td>aca/cia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>znw.</td>\n",
       "      <td>de[m.]</td>\n",
       "      <td>acacia@@s</td>\n",
       "      <td>aca/cia@@s</td>\n",
       "      <td>acaciaatje:</td>\n",
       "      <td>aca/ci/a/tje</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>accu</td>\n",
       "      <td>ac/cu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>znw.</td>\n",
       "      <td>de[m.]</td>\n",
       "      <td>accu@@s</td>\n",
       "      <td>ac/cu@@s</td>\n",
       "      <td>accuutje:</td>\n",
       "      <td>ac/cu/tje</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>agenda</td>\n",
       "      <td>agen/da</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>znw.</td>\n",
       "      <td>de</td>\n",
       "      <td>agenda@@s</td>\n",
       "      <td>agen/da@@s</td>\n",
       "      <td>agendaatje:</td>\n",
       "      <td>agen/da/tje</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>amfora</td>\n",
       "      <td>am/fo/ra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>znw.</td>\n",
       "      <td>de</td>\n",
       "      <td>amfora@@s</td>\n",
       "      <td>am/fo/ra@@s</td>\n",
       "      <td>amforaatje:</td>\n",
       "      <td>am/fo/ra/tje</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word syllables see also disambiguation grammatical tag article  \\\n",
       "1051     abc       abc      NaN            NaN            znw.     het   \n",
       "1163  acacia   aca/cia      NaN            NaN            znw.  de[m.]   \n",
       "1248    accu     ac/cu      NaN            NaN            znw.  de[m.]   \n",
       "2981  agenda   agen/da      NaN            NaN            znw.      de   \n",
       "3751  amfora  am/fo/ra      NaN            NaN            znw.      de   \n",
       "\n",
       "     plural/past/attrib plural/past/attrib syllables  \\\n",
       "1051             abc@@s                       abc@@s   \n",
       "1163          acacia@@s                   aca/cia@@s   \n",
       "1248            accu@@s                     ac/cu@@s   \n",
       "2981          agenda@@s                   agen/da@@s   \n",
       "3751          amfora@@s                  am/fo/ra@@s   \n",
       "\n",
       "     diminu/compara/past plural diminu/compara/past plural syllables  \\\n",
       "1051                  abc@@tje:                              abc/tje   \n",
       "1163                acaciaatje:                         aca/ci/a/tje   \n",
       "1248                  accuutje:                            ac/cu/tje   \n",
       "2981                agendaatje:                          agen/da/tje   \n",
       "3751                amforaatje:                         am/fo/ra/tje   \n",
       "\n",
       "     past perfect/superla past perfect/superla syllables  \n",
       "1051                  NaN                            NaN  \n",
       "1163                  NaN                            NaN  \n",
       "1248                  NaN                            NaN  \n",
       "2981                  NaN                            NaN  \n",
       "3751                  NaN                            NaN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GB1995_colon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have no idea what this means, so will just filter it out.\n",
    "\n",
    "Also, there are \"words\" that are actually several words... arrggh!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_comma = wordform_df.str.contains(', ')\n",
    "wordform_df = pd.concat((wordform_df[~has_comma],) + tuple(pd.Series(row.split(', ')) for row in wordform_df[has_comma]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform_df[wordform_df.str.contains(', ')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out crap\n",
    "- Colons behind some words: we remove the colons and leave the rest of the word in.\n",
    "- Words that are in fact several words, like \"aan weerszijden\" or \"schoof vooruit\". Remove those entries, split the words and append them to the end.\n",
    "- Strip whitespace from either end of words (some apparently have it).\n",
    "- Remove \"footnote\" numbers postfixed to duplicate words: like with colons.\n",
    "- Retain only unique words after the above procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102905             vrijdagse\n",
       "9100          beroepsrenners\n",
       "105005           bliezen weg\n",
       "42577     karaktertekeningen\n",
       "47865              kurkenzak\n",
       "29831           gemotiveerde\n",
       "89622       tegenwoordigheid\n",
       "52920                 mammie\n",
       "92704        getranscendeerd\n",
       "78648            schaduwvlek\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw some samples to check for remaining weird shit\n",
    "wordform_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove colons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordform_df = wordform_df.str.replace(':', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform_df[wordform_df.str.contains(':')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split multiple word entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surround space with any-character, because some single words also just have space padding\n",
    "multi_word = wordform_df.str.contains('. .', regex=True)\n",
    "wordform_df = pd.concat((wordform_df[~multi_word],) + tuple(pd.Series(row.split(' ')) for row in wordform_df[multi_word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform_df[wordform_df.str.contains('. .')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strip whitespace\n",
    "Ok, so it's actually just one word, but still."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ganzenvederen \n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform_df[wordform_df.str.contains(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordform_df = wordform_df.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform_df[wordform_df.str.contains(' ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove duplicate word footnote numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = wordform_df.str.contains('[0-9]$', regex=True)\n",
    "wordform_df = pd.concat((wordform_df[~duplicates], wordform_df[duplicates].str.replace('[0-9]$', '', regex=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    schrikpoeder\n",
       " 0       tegengift\n",
       " 0       voldoende\n",
       " 0     zweetpoeder\n",
       " 0     zweetpoeder\n",
       " dtype: object, Series([], dtype: object))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform_df.tail(), wordform_df[wordform_df.str.contains('[0-9]$', regex=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retain only unique wordforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordform_df = pd.Series(wordform_df.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190783            (etc.)\n",
       "190750          (kwader)\n",
       "101204          (werken)\n",
       "190719               @@s\n",
       "77526     @@s-Gravenhage\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform_df.sort_values().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra: remove stuff between parentheses\n",
    "This turned up when sorting. We should remove \"etc.\", which is a abbreviation, but we could keep the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordform_df = wordform_df.sort_values().str.strip(\"()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190783              etc.\n",
       "190750            kwader\n",
       "101204            werken\n",
       "190719               @@s\n",
       "77526     @@s-Gravenhage\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra 2: abbreviations\n",
    "Are there any more of them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190783                  etc.\n",
       "5677                      B.\n",
       "50019                     M.\n",
       "6750                     bc.\n",
       "20974                    dr.\n",
       "21536                   drs.\n",
       "21537             drs.-titel\n",
       "21745                    ds.\n",
       "37653                   ing.\n",
       "38928                    ir.\n",
       "48211                   lic.\n",
       "54726                    mr.\n",
       "68916                  prof.\n",
       "82795       st.-jakobsschelp\n",
       "156117    st.-jakobsschelpen\n",
       "191083              vademen.\n",
       "dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform_df[wordform_df.str.contains('.', regex=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we remove the ones that are \"pure\" abbreviations, i.e. that end in a period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviation = wordform_df.str.contains('\\.$')\n",
    "wordform_df = wordform_df[~abbreviation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21537             drs.-titel\n",
       "82795       st.-jakobsschelp\n",
       "156117    st.-jakobsschelpen\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform_df[wordform_df.str.contains('.', regex=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra 3: Retain only unique wordforms... again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordform_df = pd.Series(wordform_df.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2                  @@s\n",
       "3       @@s-Gravenhage\n",
       "4    @@s-Hertogenbosch\n",
       "5                  @@t\n",
       "6             A-biljet\n",
       "dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform_df.sort_values().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is a problem. \"'s\" is not a separate word, it really belongs to some other word, that we split it off from.\n",
    "\n",
    "### Aaaand again\n",
    "\n",
    "After discussion, we decided to keep in the multi-word wordforms after all. We will see how to deal with them in TICCL later.\n",
    "\n",
    "For the occasion, let's also just put everything in one function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordform_df = pd.concat((df_GB1995[\"word\"],\n",
    "                         df_GB1995[\"plural/past/attrib\"],\n",
    "                         df_GB1995[\"diminu/compara/past plural\"],\n",
    "                         df_GB1995[\"past perfect/superla\"]))\\\n",
    "                .dropna()\n",
    "has_comma = wordform_df.str.contains(', ')\n",
    "wordform_df = pd.concat((wordform_df[~has_comma],) + tuple(pd.Series(row.split(', ')) for row in wordform_df[has_comma]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_wordform_df(wordform_df):\n",
    "    # remove colons\n",
    "    wordform_df = wordform_df.str.replace(':', '')\n",
    "    # strip whitespace\n",
    "    wordform_df = wordform_df.str.strip()\n",
    "    # remove duplicate word footnote numbers\n",
    "    duplicates = wordform_df.str.contains('[0-9]$', regex=True)\n",
    "    wordform_df = pd.concat((wordform_df[~duplicates], wordform_df[duplicates].str.replace('[0-9]$', '', regex=True)))\n",
    "    # remove parentheses around some words\n",
    "    wordform_df = wordform_df.sort_values().str.strip(\"()\")\n",
    "    # remove abbreviations\n",
    "    abbreviation = wordform_df.str.contains('\\.$')\n",
    "    wordform_df = wordform_df[~abbreviation]\n",
    "    # remove duplicates\n",
    "    wordform_df = pd.Series(wordform_df.unique())\n",
    "    return wordform_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordform_clean_df = clean_wordform_df(wordform_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cleanliness_wordform_df(wordform_df, head=5):\n",
    "    print(\"Random sample:\")\n",
    "    display(wordform_df.sample(10))\n",
    "    print(\"Colons, periods:\")\n",
    "    display(wordform_df[wordform_df.str.contains(':')].head(head))\n",
    "    display(wordform_df[wordform_df.str.contains('.', regex=False)].head(head))\n",
    "    print(\"White space padding:\")\n",
    "    display(wordform_df[wordform_df.str.contains('^ | $')].head(head))\n",
    "    print(\"Trailing numbers:\")\n",
    "    display(wordform_df[wordform_df.str.contains('[0-9]$', regex=True)].head(head))\n",
    "    print(\"Parentheses:\")\n",
    "    display(wordform_df[wordform_df.str.contains('\\(|\\)', regex=True)].head(head))\n",
    "    print(\"Abbreviations:\")\n",
    "    display(wordform_df[wordform_df.str.contains('\\.$')].head(head))\n",
    "    \n",
    "    print(\"Finally, just the first entries of sorted df:\")\n",
    "    display(wordform_df.sort_values().head(head))\n",
    "    display(wordform_df.sort_values().tail(head))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58126             natiewagens\n",
       "5544                 autogiro\n",
       "47255              sloot krom\n",
       "101994    voorlichtingsbudget\n",
       "35218               helpertje\n",
       "42493        kapitein-vlieger\n",
       "21581          verhuurde door\n",
       "62513        onmenselijkheden\n",
       "64831               opruimers\n",
       "9465               bestelling\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colons, periods:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4321         AOW@@er:\n",
       "15233        CDA@@er:\n",
       "15664    chocolaatje:\n",
       "16259    collegaatje:\n",
       "23720       EHBO@@er:\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5876             B.\n",
       "7000            bc.\n",
       "21845           dr.\n",
       "22433          drs.\n",
       "22434    drs.-titel\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White space padding:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    ganzenvederen \n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trailing numbers:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8     aak1\n",
       "9     aak2\n",
       "10    aal1\n",
       "11    aal2\n",
       "12    aal3\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parentheses:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10920    bij zijn positieve(n) zijn\n",
       "38867       in de(n) piepzak zitten\n",
       "55917                 mine(s) maken\n",
       "64077          op de(n) dompel zijn\n",
       "64078                 op de(n) duur\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abbreviations:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5876       B.\n",
       "7000      bc.\n",
       "21845     dr.\n",
       "22433    drs.\n",
       "22649     ds.\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finally, just the first entries of sorted df:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "107697             (werken)\n",
       "105814             (werken)\n",
       "78215      @@s anderendaags\n",
       "81091        @@s-Gravenhage\n",
       "81109     @@s-Hertogenbosch\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1                          zwoord\n",
       "1                        zwoorden\n",
       "2974        zworen af zweerden af\n",
       "95084     zworen uit zweerden uit\n",
       "110578            zworen zweerden\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_cleanliness_wordform_df(wordform_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71594          imperfectum\n",
       "18104      bestuurskundige\n",
       "170805            vanboven\n",
       "84637     koopmanstraditie\n",
       "68571          hoofdmannen\n",
       "150246          spieringen\n",
       "72108             indiaans\n",
       "138332           rouwkoets\n",
       "22236          blueszanger\n",
       "23861              borduur\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colons, periods:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "40318                 drs.-titel\n",
       "151892          st.-jakobsschelp\n",
       "151893        st.-jakobsschelpen\n",
       "161098    ten tweede (etc.) male\n",
       "170166           vademen. vadems\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White space padding:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trailing numbers:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parentheses:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19892     bij zijn positieve(n) zijn\n",
       "71770        in de(n) piepzak zitten\n",
       "101371                 mine(s) maken\n",
       "115273          op de(n) dompel zijn\n",
       "115274                 op de(n) duur\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abbreviations:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finally, just the first entries of sorted df:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1              @@s anderendaags\n",
       "2                @@s-Gravenhage\n",
       "3             @@s-Hertogenbosch\n",
       "4    @@t is dief en diefjesmaat\n",
       "5                      A-biljet\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "196929                     zwoord\n",
       "196930                   zwoorden\n",
       "196931      zworen af zweerden af\n",
       "196932    zworen uit zweerden uit\n",
       "196933            zworen zweerden\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_cleanliness_wordform_df(wordform_clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there's some remaining issues here that should be at least duly noted (though ideally dealt with):\n",
    "\n",
    "- Some words have `(etc.)` in it, like `ten tweede (etc.) male`. This should be expanded into `ten derde male`, and so forth for all counting words.\n",
    "- Other parenthesized words like `op de(n) duur` should be considered as two words, `op de duur` and `op den duur`.\n",
    "- I'm not sure what the period in `vademen. vadems` means, though I suspect the period is a mistyped comma.\n",
    "\n",
    "**We will leave these things as they are for now.**\n",
    "\n",
    "One more pressing remaining issue is that there are apparently \"multiple words\" that are not separated by comma at all! See `zworen af zweerde af` which should be two terms. Let's check what this looks like in the original table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>syllables</th>\n",
       "      <th>see also</th>\n",
       "      <th>disambiguation</th>\n",
       "      <th>grammatical tag</th>\n",
       "      <th>article</th>\n",
       "      <th>plural/past/attrib</th>\n",
       "      <th>plural/past/attrib syllables</th>\n",
       "      <th>diminu/compara/past plural</th>\n",
       "      <th>diminu/compara/past plural syllables</th>\n",
       "      <th>past perfect/superla</th>\n",
       "      <th>past perfect/superla syllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>afzweren1</td>\n",
       "      <td>af/zwe/ren</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(door verzwering afvallen)</td>\n",
       "      <td>ww.min_zich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwoor af zweerde af</td>\n",
       "      <td>zwoor af zweer/de af</td>\n",
       "      <td>zworen af zweerden af</td>\n",
       "      <td>zwo/ren af zweer/den af</td>\n",
       "      <td>afgezworen</td>\n",
       "      <td>af/ge/zwo/ren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>afzweren2</td>\n",
       "      <td>af/zwe/ren</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(onder ede verwerpen)</td>\n",
       "      <td>ww.min_zich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwoer af</td>\n",
       "      <td>zwoer af</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>afgezworen</td>\n",
       "      <td>af/ge/zwo/ren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10467</th>\n",
       "      <td>bezweren</td>\n",
       "      <td>be/zwe/ren</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ww.min_zich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bezwoer</td>\n",
       "      <td>be/zwoer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bezworen</td>\n",
       "      <td>be/zwo/ren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40629</th>\n",
       "      <td>inzweren</td>\n",
       "      <td>in/zwe/ren</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ww.min_zich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ingezworen</td>\n",
       "      <td>in/ge/zwo/ren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78181</th>\n",
       "      <td>samenzweren</td>\n",
       "      <td>sa/men/zwe/ren</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ww.min_zich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwoer samen</td>\n",
       "      <td>zwoer sa/men</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>samengezworen</td>\n",
       "      <td>sa/men/ge/zwo/ren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95084</th>\n",
       "      <td>uitzweren</td>\n",
       "      <td>uit/zwe/ren</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ww.min_zich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwoor uit zweerde uit</td>\n",
       "      <td>zwoor uit zweer/de uit</td>\n",
       "      <td>zworen uit zweerden uit</td>\n",
       "      <td>zwo/ren uit zweer/den uit</td>\n",
       "      <td>uitgezworen</td>\n",
       "      <td>uit/ge/zwo/ren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99524</th>\n",
       "      <td>verzweren</td>\n",
       "      <td>ver/zwe/ren</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ww.min_zich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>verzwoor verzweerde</td>\n",
       "      <td>ver/zwoor ver/zweer/de</td>\n",
       "      <td>verzworen verzweerden</td>\n",
       "      <td>ver/zwo/ren ver/zweer/den</td>\n",
       "      <td>verzworen</td>\n",
       "      <td>ver/zwo/ren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110577</th>\n",
       "      <td>zweren1</td>\n",
       "      <td>zwe/ren</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(een eed doen)</td>\n",
       "      <td>ww.min_zich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwoer</td>\n",
       "      <td>zwoer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gezworen</td>\n",
       "      <td>ge/zwo/ren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110578</th>\n",
       "      <td>zweren2</td>\n",
       "      <td>zwe/ren</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(etteren)</td>\n",
       "      <td>ww.min_zich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zwoor zweerde</td>\n",
       "      <td>zwoor zweer/de</td>\n",
       "      <td>zworen zweerden</td>\n",
       "      <td>zwo/ren zweer/den</td>\n",
       "      <td>gezworen</td>\n",
       "      <td>ge/zwo/ren</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word       syllables see also              disambiguation  \\\n",
       "2974      afzweren1      af/zwe/ren      NaN  (door verzwering afvallen)   \n",
       "2975      afzweren2      af/zwe/ren      NaN       (onder ede verwerpen)   \n",
       "10467      bezweren      be/zwe/ren      NaN                         NaN   \n",
       "40629      inzweren      in/zwe/ren      NaN                         NaN   \n",
       "78181   samenzweren  sa/men/zwe/ren      NaN                         NaN   \n",
       "95084     uitzweren     uit/zwe/ren      NaN                         NaN   \n",
       "99524     verzweren     ver/zwe/ren      NaN                         NaN   \n",
       "110577      zweren1         zwe/ren      NaN              (een eed doen)   \n",
       "110578      zweren2         zwe/ren      NaN                   (etteren)   \n",
       "\n",
       "       grammatical tag article     plural/past/attrib  \\\n",
       "2974       ww.min_zich     NaN    zwoor af zweerde af   \n",
       "2975       ww.min_zich     NaN               zwoer af   \n",
       "10467      ww.min_zich     NaN                bezwoer   \n",
       "40629      ww.min_zich     NaN                    NaN   \n",
       "78181      ww.min_zich     NaN            zwoer samen   \n",
       "95084      ww.min_zich     NaN  zwoor uit zweerde uit   \n",
       "99524      ww.min_zich     NaN    verzwoor verzweerde   \n",
       "110577     ww.min_zich     NaN                  zwoer   \n",
       "110578     ww.min_zich     NaN          zwoor zweerde   \n",
       "\n",
       "       plural/past/attrib syllables diminu/compara/past plural  \\\n",
       "2974           zwoor af zweer/de af      zworen af zweerden af   \n",
       "2975                       zwoer af                        NaN   \n",
       "10467                      be/zwoer                        NaN   \n",
       "40629                           NaN                        NaN   \n",
       "78181                  zwoer sa/men                        NaN   \n",
       "95084        zwoor uit zweer/de uit    zworen uit zweerden uit   \n",
       "99524        ver/zwoor ver/zweer/de      verzworen verzweerden   \n",
       "110577                        zwoer                        NaN   \n",
       "110578               zwoor zweer/de            zworen zweerden   \n",
       "\n",
       "       diminu/compara/past plural syllables past perfect/superla  \\\n",
       "2974                zwo/ren af zweer/den af           afgezworen   \n",
       "2975                                    NaN           afgezworen   \n",
       "10467                                   NaN             bezworen   \n",
       "40629                                   NaN           ingezworen   \n",
       "78181                                   NaN        samengezworen   \n",
       "95084             zwo/ren uit zweer/den uit          uitgezworen   \n",
       "99524             ver/zwo/ren ver/zweer/den            verzworen   \n",
       "110577                                  NaN             gezworen   \n",
       "110578                    zwo/ren zweer/den             gezworen   \n",
       "\n",
       "       past perfect/superla syllables  \n",
       "2974                    af/ge/zwo/ren  \n",
       "2975                    af/ge/zwo/ren  \n",
       "10467                      be/zwo/ren  \n",
       "40629                   in/ge/zwo/ren  \n",
       "78181               sa/men/ge/zwo/ren  \n",
       "95084                  uit/ge/zwo/ren  \n",
       "99524                     ver/zwo/ren  \n",
       "110577                     ge/zwo/ren  \n",
       "110578                     ge/zwo/ren  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GB1995[df_GB1995['word'].str.contains('zweren', na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No idea how to fix this... **yet**. Leave it as is for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing diacritics\n",
    "\n",
    "TICCLAT has unicode wordforms, so we can just replace the diacritic markers with actual diacritics. How to do that?\n",
    "\n",
    "Apparently, there is such a thing as \"combining characters\" in Unicode: https://stackoverflow.com/questions/34755556/how-do-i-add-accents-to-a-letter. Nice! Here's a table of them: https://en.wikipedia.org/wiki/Combining_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that these are regex formatted, i.e. with special characters escaped\n",
    "diacritic_markers = {'@`': '\\u0300',    # accent grave\n",
    "                     \"@\\\\'\": '\\u0301',  # accent aigu\n",
    "                     '@\\\\\\\\': '\\u0308', # trema\n",
    "                     '@\\+': '\\u0327',   # cedilla\n",
    "                     '@\\^': '\\u0302',   # accent circumflex\n",
    "                     '@=': '\\u0303',    # tilde\n",
    "                     '@@': \"'\",         # apostrophe (not actually a diacritic)\n",
    "                     '@2': '\\u2082',    # subscript 2\n",
    "                     '@n': '\\u0308n'    # trema followed by n\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for marker, umarker in diacritic_markers.items():\n",
    "    wordform_clean_df = wordform_clean_df.str.replace(marker, umarker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1               's anderendaags\n",
       "2                 's-Gravenhage\n",
       "3              's-Hertogenbosch\n",
       "4     't is dief en diefjesmaat\n",
       "5                      A-biljet\n",
       "6                   A-biljetten\n",
       "7                         A-bom\n",
       "8                      A-bommen\n",
       "9                      A-omroep\n",
       "10                   A-omroepen\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordform_clean_df.sort_values().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Groene Boekje DataFrames into TICCLAT database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0396c7d57495446096b17f87ae360a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'latin-1' codec can't encode character '\\u0308' in position 14: ordinal not in range(256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-22e27abe721c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mticclat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mticclat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_lexicon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Groene Boekje 1995\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordform_clean_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wordform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/ticclat/ticclat/ticclat/dbutils.py\u001b[0m in \u001b[0;36madd_lexicon\u001b[0;34m(session, lexicon_name, wfs, num)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32min\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mjust\u001b[0m \u001b[0;34m\"wordform\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \"\"\"\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mbulk_add_wordforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mlexicon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLexicon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexicon_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlexicon_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ticclat/ticclat/ticclat/dbutils.py\u001b[0m in \u001b[0;36mbulk_add_wordforms\u001b[0;34m(session, wfs, num)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWordform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWordform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwordform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mexisting_wfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwordform\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36mall\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2924\u001b[0m         \"\"\"\n\u001b[0;32m-> 2925\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_generative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_no_clauseelement_condition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3079\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autoflush\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_populate_existing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3080\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autoflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3081\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_and_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36m_execute_and_instances\u001b[0;34m(self, querycontext)\u001b[0m\n\u001b[1;32m   3104\u001b[0m         )\n\u001b[1;32m   3105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3106\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquerycontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquerycontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquerycontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, object_, *multiparams, **params)\u001b[0m\n\u001b[1;32m    978\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectNotExecutableError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/sql/elements.py\u001b[0m in \u001b[0;36m_execute_on_connection\u001b[0;34m(self, connection, multiparams, params)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_on_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_execution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_clauseelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectNotExecutableError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_clauseelement\u001b[0;34m(self, elem, multiparams, params)\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0mdistilled_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0mcompiled_sql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m             \u001b[0mdistilled_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m         )\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m             self._handle_dbapi_exception(\n\u001b[0;32m-> 1240\u001b[0;31m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m             )\n\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1458\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_cause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb, cause)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m                     self.dialect.do_execute(\n\u001b[0;32m-> 1236\u001b[0;31m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     )\n\u001b[1;32m   1238\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/MySQLdb/cursors.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, args)\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mPY2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/MySQLdb/connections.py\u001b[0m in \u001b[0;36mliteral\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tuple_literal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# Python 3(~3.4) doesn't support % operation for bytes object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# We should decode it before using %.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/MySQLdb/connections.py\u001b[0m in \u001b[0;36municode_literal\u001b[0;34m(u, dummy)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;31m# unicode_literal() is called for arbitrary object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0municode_literal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_literal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mbytes_literal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'latin-1' codec can't encode character '\\u0308' in position 14: ordinal not in range(256)"
     ]
    }
   ],
   "source": [
    "with ticclat.dbutils.session_scope(Session) as session:\n",
    "    ticclat.dbutils.add_lexicon(session, \"Groene Boekje 1995\", wordform_clean_df.to_frame(name='wordform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is giving me an error\n",
    "\n",
    "```python-traceback\n",
    "---------------------------------------------------------------------------\n",
    "UnicodeEncodeError                        Traceback (most recent call last)\n",
    "<ipython-input-93-22e27abe721c> in <module>\n",
    "      1 with ticclat.dbutils.session_scope(Session) as session:\n",
    "----> 2     ticclat.dbutils.add_lexicon(session, \"Groene Boekje 1995\", wordform_clean_df.to_frame(name='wordform'))\n",
    "\n",
    "~/projects/ticclat/ticclat/ticclat/dbutils.py in add_lexicon(session, lexicon_name, wfs, num)\n",
    "     97     in this case just \"wordform\"\n",
    "     98     \"\"\"\n",
    "---> 99     bulk_add_wordforms(session, wfs, num=num)\n",
    "    100 \n",
    "    101     lexicon = Lexicon(lexicon_name=lexicon_name)\n",
    "\n",
    "~/projects/ticclat/ticclat/ticclat/dbutils.py in bulk_add_wordforms(session, wfs, num)\n",
    "     72 \n",
    "     73         q = session.query(Wordform)\n",
    "---> 74         result = q.filter(Wordform.wordform.in_(wordforms)).all()\n",
    "     75 \n",
    "     76         existing_wfs = [wf.wordform for wf in result]\n",
    "\n",
    "~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/orm/query.py in all(self)\n",
    "   2923 \n",
    "   2924         \"\"\"\n",
    "-> 2925         return list(self)\n",
    "   2926 \n",
    "   2927     @_generative(_no_clauseelement_condition)\n",
    "\n",
    "~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/orm/query.py in __iter__(self)\n",
    "   3079         if self._autoflush and not self._populate_existing:\n",
    "   3080             self.session._autoflush()\n",
    "-> 3081         return self._execute_and_instances(context)\n",
    "   3082 \n",
    "   3083     def __str__(self):\n",
    "\n",
    "~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/orm/query.py in _execute_and_instances(self, querycontext)\n",
    "   3104         )\n",
    "   3105 \n",
    "-> 3106         result = conn.execute(querycontext.statement, self._params)\n",
    "   3107         return loading.instances(querycontext.query, result, querycontext)\n",
    "   3108 \n",
    "\n",
    "~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/engine/base.py in execute(self, object_, *multiparams, **params)\n",
    "    978             raise exc.ObjectNotExecutableError(object_)\n",
    "    979         else:\n",
    "--> 980             return meth(self, multiparams, params)\n",
    "    981 \n",
    "    982     def _execute_function(self, func, multiparams, params):\n",
    "\n",
    "~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/sql/elements.py in _execute_on_connection(self, connection, multiparams, params)\n",
    "    271     def _execute_on_connection(self, connection, multiparams, params):\n",
    "    272         if self.supports_execution:\n",
    "--> 273             return connection._execute_clauseelement(self, multiparams, params)\n",
    "    274         else:\n",
    "    275             raise exc.ObjectNotExecutableError(self)\n",
    "\n",
    "~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_clauseelement(self, elem, multiparams, params)\n",
    "   1097             distilled_params,\n",
    "   1098             compiled_sql,\n",
    "-> 1099             distilled_params,\n",
    "   1100         )\n",
    "   1101         if self._has_events or self.engine._has_events:\n",
    "\n",
    "~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_context(self, dialect, constructor, statement, parameters, *args)\n",
    "   1238         except BaseException as e:\n",
    "   1239             self._handle_dbapi_exception(\n",
    "-> 1240                 e, statement, parameters, cursor, context\n",
    "   1241             )\n",
    "   1242 \n",
    "\n",
    "~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _handle_dbapi_exception(self, e, statement, parameters, cursor, context)\n",
    "   1458                 util.raise_from_cause(sqlalchemy_exception, exc_info)\n",
    "   1459             else:\n",
    "-> 1460                 util.reraise(*exc_info)\n",
    "   1461 \n",
    "   1462         finally:\n",
    "\n",
    "~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/util/compat.py in reraise(tp, value, tb, cause)\n",
    "    275         if value.__traceback__ is not tb:\n",
    "    276             raise value.with_traceback(tb)\n",
    "--> 277         raise value\n",
    "    278 \n",
    "    279 \n",
    "\n",
    "~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/engine/base.py in _execute_context(self, dialect, constructor, statement, parameters, *args)\n",
    "   1234                 if not evt_handled:\n",
    "   1235                     self.dialect.do_execute(\n",
    "-> 1236                         cursor, statement, parameters, context\n",
    "   1237                     )\n",
    "   1238         except BaseException as e:\n",
    "\n",
    "~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/engine/default.py in do_execute(self, cursor, statement, parameters, context)\n",
    "    534 \n",
    "    535     def do_execute(self, cursor, statement, parameters, context=None):\n",
    "--> 536         cursor.execute(statement, parameters)\n",
    "    537 \n",
    "    538     def do_execute_no_params(self, cursor, statement, context=None):\n",
    "\n",
    "~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/MySQLdb/cursors.py in execute(self, query, args)\n",
    "    237                 args = dict((key, db.literal(item)) for key, item in args.items())\n",
    "    238             else:\n",
    "--> 239                 args = tuple(map(db.literal, args))\n",
    "    240             if not PY2 and isinstance(query, (bytes, bytearray)):\n",
    "    241                 query = query.decode(db.encoding)\n",
    "\n",
    "~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/MySQLdb/connections.py in literal(self, o)\n",
    "    319             s = self._tuple_literal(o)\n",
    "    320         else:\n",
    "--> 321             s = self.escape(o, self.encoders)\n",
    "    322         # Python 3(~3.4) doesn't support % operation for bytes object.\n",
    "    323         # We should decode it before using %.\n",
    "\n",
    "~/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/MySQLdb/connections.py in unicode_literal(u, dummy)\n",
    "    227             # unicode_literal() is called for arbitrary object.\n",
    "    228             def unicode_literal(u, dummy=None):\n",
    "--> 229                 return db.string_literal(str(u).encode(db.encoding))\n",
    "    230 \n",
    "    231         def bytes_literal(obj, dummy=None):\n",
    "\n",
    "UnicodeEncodeError: 'latin-1' codec can't encode character '\\u0308' in position 14: ordinal not in range(256)\n",
    "```\n",
    "\n",
    "It seems like the `db.encoding` for some reason is latin-1 there, even though we set the ticclat database to be utf8 in MySQL using\n",
    "\n",
    "```mysql\n",
    "CREATE DATABASE ticclat CHARACTER SET utf8mb4 COLLATE utf8mb4_bin;\n",
    "```\n",
    "\n",
    "This is a guide that should set everything to utf8: https://mathiasbynens.be/notes/mysql-utf8mb4#mysql-utf8mb4\n",
    "\n",
    "The important part there that we're still missing is that `character_set_client` may still be non-utf8, i.e. clients could still read the data as latin-1, even though the database is encoded as utf8 (see e.g. https://nicj.net/mysql-converting-an-incorrect-latin1-column-to-utf8/). In my case it seems like its neither latin-1 nor utf8mb4, but actually \"utf8\" which is an alias for utf8mb3 (see https://stackoverflow.com/a/30074553/1199693), as I found out by running `SHOW VARIABLES LIKE 'character_set_client';`.\n",
    "\n",
    "We will do this by creating a configuration file. To find out which file your client reads from, run this:\n",
    "```sh\n",
    "mysql --help | grep -A 1 \"Default options are read from the following files\"\n",
    "```\n",
    "\n",
    "For me this gives\n",
    "```sh\n",
    "Default options are read from the following files in the given order:\n",
    "/etc/my.cnf /etc/mysql/my.cnf /Users/pbos/sw/miniconda3/envs/ticclat2/etc/my.cnf ~/.my.cnf\n",
    "```\n",
    "\n",
    "I'm using MySQL from Conda, so I'll use the miniconda location and put this in the file:\n",
    "\n",
    "```ini\n",
    "[client]\n",
    "default-character-set = utf8mb4\n",
    "\n",
    "[mysql]\n",
    "default-character-set = utf8mb4\n",
    "\n",
    "[mysqld]\n",
    "character-set-client-handshake = FALSE\n",
    "character-set-server = utf8mb4\n",
    "collation-server = utf8mb4_unicode_ci\n",
    "```\n",
    "\n",
    "Then restart the server and recreate the database (don't care much about saving data at this point) by deleting and recreating.\n",
    "\n",
    "```sh\n",
    "mysqld restart\n",
    "```\n",
    "\n",
    "Indeed, now `SHOW VARIABLES LIKE 'character_set_client';` gives utf8mb4.\n",
    "\n",
    ".......\n",
    "\n",
    "Ok, never mind, I was using the \"groene_boekje\" database, not the \"ticclat\" database. D'oh!\n",
    "\n",
    ".......\n",
    "\n",
    "Ok, but with that fixed, the problem still persists. Even with the whole configuration file above added... crap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c831eef158c74ef4a639e7a059f7e04b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pbos/sw/miniconda3/envs/ticclat2/lib/python3.7/site-packages/sqlalchemy/engine/default.py:536: Warning: (3170, '')\n",
      "  cursor.execute(statement, parameters)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "196934\n"
     ]
    }
   ],
   "source": [
    "with ticclat.dbutils.session_scope(Session) as session:\n",
    "    ticclat.dbutils.add_lexicon(session, \"Groene Boekje 1995\", wordform_clean_df.str.encode('utf8').to_frame(name='wordform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yaaay, that seems to have worked! The crucial addition there is `.str.encode('utf-8')`. Actually, we already discussed this, but I got lost in the MySQL settings and forgot.\n",
    "\n",
    "This is also useful to check the encoding of tables themselves:\n",
    "```mysql\n",
    "SELECT T.table_name, CCSA.character_set_name FROM information_schema.`TABLES` T,\n",
    "information_schema.`COLLATION_CHARACTER_SET_APPLICABILITY` CCSA\n",
    "WHERE CCSA.collation_name = T.table_collation AND T.table_schema = \"ticclat\";\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But also have to make sure that the data is put in correctly. Just browsing through the data in mysql with\n",
    "\n",
    "```mysql\n",
    "SELECT * FROM wordforms;\n",
    "```\n",
    "\n",
    "Shows that the unicode words are not displayed correctly in the terminal at least, e.g. `zooloog\"` instead of `zoloog`.\n",
    "\n",
    "How about if we query from here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zooloog'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'zoo{}loog'.format(diacritic_markers['@\\\\\\\\'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Wordform zooloog\">\n"
     ]
    }
   ],
   "source": [
    "# again gives long utf-8/latin-1 UnicodeEncodeError:\n",
    "# with ticclat.dbutils.session_scope(Session) as session:\n",
    "#     for wordform in session.query(ticclat.ticclat_schema.Wordform).filter_by(wordform='zoo{}loog'.format(diacritic_markers['@\\\\\\\\'])):\n",
    "#          print(wordform)\n",
    "\n",
    "# this gives no results at all\n",
    "with ticclat.dbutils.session_scope(Session) as session:\n",
    "    for wordform in session.query(ticclat.ticclat_schema.Wordform).filter_by(wordform='zooloog\"'.encode('utf-8')):\n",
    "         print(wordform)\n",
    "\n",
    "# ... neither does this, when I manually type in zoloog with alt-U O (on macOS) for the \n",
    "with ticclat.dbutils.session_scope(Session) as session:\n",
    "    for wordform in session.query(ticclat.ticclat_schema.Wordform).filter_by(wordform='zoloog\"'.encode('utf-8')):\n",
    "         print(wordform)\n",
    "\n",
    "# ... but when I copy-paste the output of the cell above it works!\n",
    "with ticclat.dbutils.session_scope(Session) as session:\n",
    "    for wordform in session.query(ticclat.ticclat_schema.Wordform).filter_by(wordform='zooloog\"'.encode('utf-8')):\n",
    "         print(wordform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
